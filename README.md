# Global Crocodile Species Prediction
<H2>Introduction to the Problem</H2>
<b>I am using the Global Crocodile Species Dataset from Kaggle. This dataset provides detailed information on all recognized crocodile species worldwide. It includes taxonomic classification, geographic distribution, habitat details, population estimates, and conservation statuses. The dataset provides both biological and ecological attributes to compare with. With some of the features of this dataset in mind, I want to predict the species of a crocodile based on length, weight, habitat, location, and a few other characteristics. I am considering using random forest because my dataset is moderate in size, and random forest can handle both numerical and categorical data, as well as capture non-linear relationships.</b>
<h2>Pre-processing the Data</h2>
<b>
I plan on handling missing and unknown data in the sex column with NaN and dropping irrelevant columns such as Observation ID, Observer Name, Notes, and Date of Observation. I also drop rows with missing values. From there, I'll choose a target variable. My target variable is "Common Name," and I continue by defining features x and target y. Finally, to ensure a clean numeric dataset for modeling, I identified categorical columns in X. I used one-hot encoding to turn them into numeric features, and used drop_first = True to avoid the dummy variable trap.
</b>
<h2>Data Understanding/Visualization</h2>
<b>I began by exploring the dataset and variables that might help with prediction (df.head(), df.info(), df.describe()). I used value_counts() for categorical columns to check class balance. I created histograms and box plots for numeric variables to inspect distributions and outliers. I created the countplots/barcharts for categorical distributions and for target class balance. I created the boxplots and violin plots of Length and Weight by Common Name to visualize overlap between species. Finally, the correlation heatmap was created for numeric features to detect multicollinearity and find strong numeric associations. What I learned from the visualizations is that a few species dominate the dataset, while several species have relatively few observations, and I kept this in mind for modeling and evaluation. I found overlap in length and weight distributions across multiple species, indicating that morphology alone may be insufficient for classification. Species are often associated with particular habitat types and regions. My visuals helped clarify the need to group rare countries or use stratify = in splits to preserve class balance. My evaluation plan shifted to using class precision/recall/F1 and Macro/weighted F1. Confusion matrices are also essential to show which species get confused.</b>
<h2>Modeling</h2>
<b>My primary model is Random Forest; the baseline alternatives considered were SVM/KNN, however, they are less convenient with many categorical features and require scaling. I used RandomizedSearchCV to tune n_estimators, max_depth, max_features, min_samples_split, and min_samples_leaf. Randomized search is a good trade-off for exploration in a moderate-sized search space.</b>
<h2>Evaluation</h2>
<b>I used a few metrics instead of relying on accuracy as follows. Accuracy is a general measure, but it can be misleading with class imbalance. I used the F1-score (per class), which is useful for multiclass problems. The confusion matrix shows which species are getting confused with. I used cross-validation to get robust performance estimates and to reduce variance due to a particular test/train split. The baseline Random Forest achieved a test accuracy of 0.91, while the tuned Random Forest (after hyperparameter optimization) improved to 0.975. This represents an improvement in predictive performance. The macro and weighted F1 scores increased from 0.90 to 0.98, showing that tuning improved both overall and per-class prediction consistency.</b>
<h2>Storytelling/Findings</h2>
<b> My EDA revealed that while length and weight carry importance, they overlap across species, so morphological data alone are insufficient for perfect classification. However, habitat and geographic region are strong predictors and boost classification performance. Modeling results show that Random Forest can successfully learn combinations of morphological and ecological features to predict species with reasonable accuracy. Most misclassifications the model makes happen between ecological and morphological factors in similar species, which suggests either that the features are insufficiently discriminative or that the dataset lacks enough samples for those species. The initial leading question is addressable with morphometrics and habitat/region data to achieve reasonable predictions. However, performance varies by species, and some require more or better data to reach high accuracy.</b>
<h2>Impact</h2>
<b>Conducting this analysis has the potential to allow automated species predictions. These predictions can help process field-survey data faster, allow for quicker identification of population trends, and support conservation actions. It could help scientists and agencies with their conservation efforts and properly allocate resources to regions with declining species. Publishing and predicting what species and what locations they belong to, however, can lead to potential poaching and endangerment of protected wildlife. Incorrect predications can lead to confusion and misdirected resources. There is potential for sampling bias and over-reliance on automation. Some fixes to these negative effects include anonymizing data for public settings (showing the region but not the exact location of certain species), requiring human involvement before results are published for confirmation of low-confidence or high-impact predictions, and using access controls for sensitive data and to detect bias.</b>
<h2>References</h2>
<b>https://www.kaggle.com/datasets/zadafiyabhrami/global-crocodile-species-dataset</b>
<b>I used Grammarly and ChatGPT-5 to check for grammar and sentence structure throughout my project. </b>
