# Global Crocodile Species Prediction
<H2>Introduction to the Problem</H2>
<b>I am using the Global Crocodile Species Dataset from Kaggle. This dataset provides detailed information on all recognized crocodile species across the globe. It includes taxonomic classification, geographic distribution, habitat details, population estimates, and conservation statuses. The dataset provides both biological and ecological attributes to compare with. With some of the features of this dataset in mind, I want to predict the species of a crocodile based on the length, weight, habitat, location, and few other characteristics. I am considering using random forest becuase my dataset is moderate sized, random forest can handle numerical and categorical data and can capture non-linear relationships.</b>
<h2>Pre-processing the Data</h2>
<b>
I plan on handling missing and unknown data in the sex column with NaN and dropping irrelevant columns such as Observation ID, Observer Name and Notes, and Date of Observation. I also drop rows with missing values. From there I'll choose a target variable. My target variable is "Common Name" and I continue by defining features x and target y. Finally, in order to ensure a clean numeric dataset for modeling, I identified categorical columns in X. I used one-hot encoding to turn them into numeric features, and used drop_first = True to avoid the dummy variable trap.
</b>
<h2>Data Understanding/Visualization</h2>
<b>I began by exploring the dataset and variables that might help with prediction (df.head(), df.info(), df.describe()). I used value_counts() for categorical columns to check class balance. I created the histograms and boxplots for numeric variables to inspect distributions and outliers. I created the countplots/barcharts for categorical distributions and for target calss balance. I created the boxplots and violin plots of Length and Weight by Common Name to visualize overlap between species. Finally, the correlation heatmap was created for numeric features to detect multicollinearity and find strong numeric associations. What I learned from the visualizations is how a few species dominate the dataset while several species have relatively few observations and kept this in mind for modeling and evaluation. I found overlap in length and weight distributions across multiple species, indicating that morphology alone may be insufficient for classification. Species are often associated with particular habitat types and regions. My visuals helped clarify the need to group rare countries or use stratify = in splits to preserve class balance. My evaluation plan shifted as to using class precision/recall/F1 and macro/weighted F1. Confusion matrices are also essential to show which species get confused. </b>
<h2>Modeling</h2>
<b>My primary model is Random Forest, the baseline alternatives considered were SVM/KNN however they are less convenient with many categorical features and require scaling. I used RandomizedSearchCV to tune n_estimators, max_depth, max_features, min_samples_split, and min_samples_leaf. Randomized search is a good trade-off for exploration in moderate size search.</b>
<h2>Evaluation</h2>
<b>I used a few metrics instead of just relying on accuracy as follows. Accuracy is a general measure but can be misleading with class imbalance. I used the F1-score (per class) which is useful for multiclass problems. The confusion matrix shows which species are getting confused with. I used cross-validation to get robust performance estimates and to reduce variance due to a particular test/train split. The baseline Random Forest achieved a test accuracy of 0.91, while the tuned Random Forest (after hyperparameter optimization) improved to 0.975. this represents a improvement in predictive performance. The macro and weighted F1 scores increased from 0.90 to 0.98, showing that tuning improved both overall and per-class prediction consistency.</b>
<h2>Storytelling/Findings</h2>
<b> My EDA revealed that while length and weight carry importance, they overlap across species so morphological data alone is insufficient for perfect classification. However, habitat and geographic region are strong predictors and boost classification performance considerably. Modeling results show that Random Forest can successfully learn combinations of morphological and ecological features to predict species with reasonable accuracy.The most misclassifications the model makes happen between ecological and morphological factors in similar species, which suggests either the features are insufficiently discriminative or the dataset lacks enough samples for those species. The initial leading question is addressable with morphometrics and habitat/region data we can achieve reasonable predictions. However, performance varies by species, and some require more or better data to reach high accuracy.</b>
<h2>Impact</h2>
<b></b>
<h2>References</h2>
<b>https://www.kaggle.com/datasets/zadafiyabhrami/global-crocodile-species-dataset</b>
